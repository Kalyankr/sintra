<div align="center">

# ğŸ§  Sintra

### Autonomous AI Agent for Edge Model Optimization

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/Built%20with-LangGraph-purple.svg)](https://github.com/langchain-ai/langgraph)

**Sintra** (Synthetic Intelligence for Targeted Runtime Architectures) is a fully autonomous agentic framework that optimizes Large Language Models for resource-constrained edge devices.

[Quick Start](#-quick-start) â€¢ [Features](#-key-features) â€¢ [Architecture](#-agentic-architecture) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸ¯ The Problem

Running a 70B parameter model on an 8GB RAM device is physically impossible. Manual pruning and quantization often result in "lobotomized" models that lose reasoning capabilities.

## ğŸ’¡ The Solution

An **autonomous AI agent** that:

1. **Plans** an optimization strategy based on your hardware constraints
2. **Researches** model architecture and similar successful optimizations
3. **Experiments** with compression recipes (quantization + pruning + layer dropping)
4. **Reflects** on failures and adjusts strategy
5. **Iterates** until performance targets are met

## ğŸš€ Quick Start

```bash
# Install
git clone https://github.com/Kalyankr/sintra.git
cd sintra
pip install -e .

# Run - zero flags needed!
sintra
```

That's it. Sintra auto-detects your hardware, sets smart targets, and starts optimizing.

### Common Examples

```bash
# Optimize a specific model
sintra --model-id microsoft/phi-2

# Use GPU-accelerated quantization
sintra --backend bnb --model-id meta-llama/Llama-3.2-1B

# Preview without running
sintra --dry-run

# Resume an interrupted run
sintra --resume
```

## âœ¨ Key Features

### ğŸ¤– Fully Agentic
- **Tool Calling**: 5 specialized tools for model research
- **ReAct Pattern**: Reason â†’ Act â†’ Observe loop
- **Self-Reflection**: Learns from failures automatically
- **LLM Routing**: Smart decisions on when to stop
- **Planning**: Strategic optimization before execution

### ğŸ¯ Multi-Backend Compression
| Backend | Best For | Quantization |
|---------|----------|--------------|
| **GGUF** (default) | CPU inference | 2-8 bit |
| **BitsAndBytes** | GPU inference | NF4, INT8 |
| **ONNX** | Cross-platform | INT8 |

### ğŸ“Š Baseline Accuracy Comparison
Automatically compares optimized model against the original to measure accuracy retention:

```
Accuracy Comparison:
  Original:  85.0%
  Optimized: 81.2%
  Retention: 95.5%
```

### ğŸ’¾ Persistence & Learning
- **SQLite database** tracks all experiments
- **Cross-run learning**: Agent avoids past mistakes
- **Checkpointing**: Resume interrupted optimizations

### ğŸ”§ Hardware Auto-Detection
Automatically detects CPU, RAM, GPU and calculates achievable targets:

```
ğŸ” Detected Hardware
  System: Linux (8 cores, 32GB)
  CUDA Available: Yes (RTX 4090)

ğŸ“Š Auto-calculated Targets
  Target TPS: 45 tokens/sec
  Min Accuracy: 70%
```

## ğŸ—ï¸ Agentic Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SINTRA AGENT                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ PLANNER  â”‚â”€â”€â”€â–¶â”‚           REACT ARCHITECT               â”‚    â”‚
â”‚  â”‚  (LLM)   â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚ TOOLS:                             â”‚ â”‚    â”‚
â”‚                  â”‚  â”‚ â€¢ get_model_architecture           â”‚ â”‚    â”‚
â”‚                  â”‚  â”‚ â€¢ search_similar_models            â”‚ â”‚    â”‚
â”‚                  â”‚  â”‚ â€¢ estimate_compression_impact      â”‚ â”‚    â”‚
â”‚                  â”‚  â”‚ â€¢ query_hardware_capabilities      â”‚ â”‚    â”‚
â”‚                  â”‚  â”‚ â€¢ lookup_quantization_benchmarks   â”‚ â”‚    â”‚
â”‚                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                      â”‚                          â”‚
â”‚                                      â–¼                          â”‚
â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                             â”‚ BENCHMARKER  â”‚                    â”‚
â”‚                             â”‚  (Executor)  â”‚                    â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                    â”‚                            â”‚
â”‚                                    â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ REFLECTOR â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    CRITIC    â”‚                     â”‚
â”‚  â”‚   (LLM)   â”‚            â”‚ (LLM Router) â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚        â”‚                         â”‚                              â”‚
â”‚        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚    â”‚                                     â”‚            â”‚
â”‚        â–¼    â–¼                                     â–¼            â”‚
â”‚   [Continue Loop]                            [REPORTER]        â”‚
â”‚                                               (Output)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“– CLI Reference

```bash
sintra [profile] [options]
```

### Core Options
| Flag | Default | Description |
|------|---------|-------------|
| `--model-id` | TinyLlama | HuggingFace model to optimize |
| `--backend` | gguf | Compression backend (gguf/bnb/onnx) |
| `--output-dir` | ./outputs | Output directory |

### Hardware
| Flag | Default | Description |
|------|---------|-------------|
| `--auto-detect` | âœ… ON | Auto-detect hardware (default) |
| `--no-auto-detect` | - | Use YAML profile instead |
| `--target-tps` | auto | Target tokens per second |
| `--target-accuracy` | auto | Minimum accuracy threshold |

### Evaluation
| Flag | Default | Description |
|------|---------|-------------|
| `--baseline` | âœ… ON | Compare against original model |
| `--no-baseline` | - | Skip baseline (faster) |
| `--skip-accuracy` | - | Skip accuracy evaluation |

### Agentic Features
| Flag | Default | Description |
|------|---------|-------------|
| `--simple` | - | Disable all agentic features |
| `--no-plan` | - | Disable planner |
| `--no-react` | - | Disable ReAct architect |
| `--no-reflect` | - | Disable self-reflection |
| `--no-llm-routing` | - | Use rule-based routing |

### Execution
| Flag | Description |
|------|-------------|
| `--dry-run` | Preview without execution |
| `--resume [ID]` | Resume from checkpoint |
| `--list-checkpoints` | Show available checkpoints |
| `--mock` | Use mock executor (testing) |
| `--debug` | Single loop without LLM |

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Agent Orchestration** | [LangGraph](https://github.com/langchain-ai/langgraph) |
| **LLM Integration** | [LangChain](https://github.com/langchain-ai/langchain) |
| **LLM Providers** | OpenAI, Anthropic, Google, Ollama |
| **Model Hub** | HuggingFace Hub API |
| **Compression** | llama.cpp, BitsAndBytes, ONNX Runtime |
| **Persistence** | SQLite |
| **Testing** | pytest (tests) |

## ğŸ§ª Development

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=sintra

# Format code
ruff format src tests
ruff check --fix src tests

# Debug mode (no LLM calls)
sintra --debug

# Mock mode (fast iteration)
sintra --mock
```

## ğŸ“ Project Structure

```
sintra/
â”œâ”€â”€ src/sintra/
â”‚   â”œâ”€â”€ agents/           # LangGraph nodes & tools
â”‚   â”‚   â”œâ”€â”€ factory.py    # LLM factory (OpenAI/Anthropic/Ollama)
â”‚   â”‚   â”œâ”€â”€ nodes.py      # Architect, Benchmarker, Critic, Reporter
â”‚   â”‚   â”œâ”€â”€ planner.py    # Strategic optimization planner
â”‚   â”‚   â”œâ”€â”€ react_architect.py  # ReAct pattern implementation
â”‚   â”‚   â”œâ”€â”€ reflector.py  # Self-reflection on failures
â”‚   â”‚   â””â”€â”€ tools.py      # 5 architect tools
â”‚   â”œâ”€â”€ benchmarks/       # Execution & measurement
â”‚   â”œâ”€â”€ compression/      # GGUF, BnB, ONNX backends
â”‚   â”œâ”€â”€ profiles/         # Hardware detection & profiles
â”‚   â”œâ”€â”€ persistence/      # SQLite history database
â”‚   â”œâ”€â”€ cli.py            # Command-line interface
â”‚   â””â”€â”€ main.py           # LangGraph workflow
â”œâ”€â”€ tests/                # tests
â”œâ”€â”€ profiles/             # Example hardware profiles
â””â”€â”€ outputs/              # Optimized models & configs
```
---

<div align="center">

**Built with curiosity ğŸ”¬**

[Report Bug](https://github.com/Kalyankr/sintra/issues) Â· [Request Feature](https://github.com/Kalyankr/sintra/issues)

</div>